2015-05-05 10:58:16[psd]:  [program started on Tue May  5 10:58:16 2015] 
2015-05-05 10:58:16[psd]:  [command line arguments] 
2015-05-05 10:58:16[psd]:  datafile http://torch7.s3-website-us-east-1.amazonaws.com/data/tr-berkeley-N5K-M56x56-lcn.ascii 
2015-05-05 10:58:16[psd]:  seed 1 
2015-05-05 10:58:16[psd]:  hessiansamples 500 
2015-05-05 10:58:16[psd]:  rundir outputs/psd 
2015-05-05 10:58:16[psd]:  minhessian 0.02 
2015-05-05 10:58:16[psd]:  kernelsize 9 
2015-05-05 10:58:16[psd]:  hessian false 
2015-05-05 10:58:16[psd]:  model linear 
2015-05-05 10:58:16[psd]:  maxhessian 1000 
2015-05-05 10:58:16[psd]:  nfiltersout 16 
2015-05-05 10:58:16[psd]:  tied false 
2015-05-05 10:58:16[psd]:  inputsize 25 
2015-05-05 10:58:16[psd]:  statinterval 500 
2015-05-05 10:58:16[psd]:  hessianinterval 100 
2015-05-05 10:58:16[psd]:  lambda 1 
2015-05-05 10:58:16[psd]:  etadecay 1e-05 
2015-05-05 10:58:16[psd]:  eta 0.002 
2015-05-05 10:58:16[psd]:  beta 1 
2015-05-05 10:58:16[psd]:  momentum 0 
2015-05-05 10:58:16[psd]:  dir outputs 
2015-05-05 10:58:16[psd]:  maxiter 1000 
2015-05-05 10:58:16[psd]:  threads 2 
2015-05-05 10:58:16[psd]:  nfiltersin 1 
2015-05-05 10:58:16[psd]:  v false 
2015-05-05 10:58:16[psd]:  batchsize 1 
2015-05-05 10:58:16[psd]:  wcar  
2015-05-05 10:58:16[psd]:  display true 
2015-05-05 10:58:16[psd]:  [----------------------] 
2015-05-05 10:58:30[psd]:  ==> constructed linear auto-encoder 
2015-05-05 10:59:32[psd]:  ==> training model 
2015-05-05 10:59:32[psd]:  ==> iteration = 500, average loss = 137.53237714484 
2015-05-05 10:59:32[psd]:  Decoder filters 
2015-05-05 10:59:32[psd]:  Encoder filters 
2015-05-05 10:59:32[psd]:  ==> iteration = 1000, average loss = 131.11608437105 
2015-05-05 10:59:32[psd]:  Decoder filters 
2015-05-05 10:59:32[psd]:  Encoder filters 
2015-05-05 11:01:19[psd]:  ==> training model 
2015-05-05 11:01:20[psd]:  ==> iteration = 500, average loss = 129.93630418144 
2015-05-05 11:01:20[psd]:  Decoder filters 
2015-05-05 11:01:20[psd]:  Encoder filters 
2015-05-05 11:01:20[psd]:  ==> iteration = 1000, average loss = 124.31780524136 
2015-05-05 11:01:20[psd]:  Decoder filters 
2015-05-05 11:01:20[psd]:  Encoder filters 
2015-05-05 11:03:28[psd]:  25 
2015-05-05 11:07:02[psd]:  ==> constructed linear auto-encoder 
2015-05-05 11:07:05[psd]:  
2015-05-05 11:07:11[psd]:  
2015-05-05 11:07:25[psd]:  ==> constructed linear auto-encoder 
2015-05-05 11:07:28[psd]:  1 
2015-05-05 11:07:35[psd]:  ==> constructed linear auto-encoder 
2015-05-05 11:07:39[psd]:  unsup.AutoEncoder 
2015-05-05 11:08:10[psd]:  ==> constructed linear auto-encoder 
2015-05-05 11:08:24[psd]:  ==> constructed linear auto-encoder 
2015-05-05 11:08:24[psd]:  ==> constructed linear auto-encoder 
2015-05-05 11:08:32[psd]:  unsup.AutoEncoder 
2015-05-05 11:09:19[psd]:  ==> training model 
2015-05-05 11:09:20[psd]:  ==> iteration = 500, average loss = 134.660598833 
2015-05-05 11:09:20[psd]:  Decoder filters 
2015-05-05 11:09:20[psd]:  Encoder filters 
2015-05-05 11:09:20[psd]:  ==> iteration = 1000, average loss = 119.76524276373 
2015-05-05 11:09:20[psd]:  Decoder filters 
2015-05-05 11:09:20[psd]:  Encoder filters 
2015-05-05 11:09:28[psd]:  ==> training model 
2015-05-05 11:09:29[psd]:  ==> iteration = 500, average loss = 106.79850918356 
2015-05-05 11:09:29[psd]:  Decoder filters 
2015-05-05 11:09:29[psd]:  Encoder filters 
2015-05-05 11:09:30[psd]:  ==> iteration = 1000, average loss = 104.22119640272 
2015-05-05 11:09:30[psd]:  Decoder filters 
2015-05-05 11:09:30[psd]:  Encoder filters 
2015-05-05 11:09:31[psd]:  ==> training model 
2015-05-05 11:09:31[psd]:  ==> iteration = 500, average loss = 93.233073862469 
2015-05-05 11:09:31[psd]:  Decoder filters 
2015-05-05 11:09:31[psd]:  Encoder filters 
2015-05-05 11:09:32[psd]:  ==> iteration = 1000, average loss = 91.183064731632 
2015-05-05 11:09:32[psd]:  Decoder filters 
2015-05-05 11:09:32[psd]:  Encoder filters 
2015-05-05 11:09:33[psd]:  ==> training model 
2015-05-05 11:09:33[psd]:  ==> iteration = 500, average loss = 93.318523922116 
2015-05-05 11:09:33[psd]:  Decoder filters 
2015-05-05 11:09:33[psd]:  Encoder filters 
2015-05-05 11:09:34[psd]:  ==> iteration = 1000, average loss = 86.043402739066 
2015-05-05 11:09:34[psd]:  Decoder filters 
2015-05-05 11:09:34[psd]:  Encoder filters 
2015-05-05 11:09:34[psd]:  ==> training model 
2015-05-05 11:09:35[psd]:  ==> iteration = 500, average loss = 90.380278748376 
2015-05-05 11:09:35[psd]:  Decoder filters 
2015-05-05 11:09:35[psd]:  Encoder filters 
2015-05-05 11:09:36[psd]:  ==> iteration = 1000, average loss = 84.077947509124 
2015-05-05 11:09:36[psd]:  Decoder filters 
2015-05-05 11:09:36[psd]:  Encoder filters 
2015-05-05 11:09:37[psd]:  ==> training model 
2015-05-05 11:09:37[psd]:  ==> iteration = 500, average loss = 86.071881478295 
2015-05-05 11:09:37[psd]:  Decoder filters 
2015-05-05 11:09:37[psd]:  Encoder filters 
2015-05-05 11:09:38[psd]:  ==> iteration = 1000, average loss = 90.928598425939 
2015-05-05 11:09:38[psd]:  Decoder filters 
2015-05-05 11:09:38[psd]:  Encoder filters 
2015-05-05 11:09:38[psd]:  ==> training model 
2015-05-05 11:09:39[psd]:  ==> iteration = 500, average loss = 84.910417429257 
2015-05-05 11:09:39[psd]:  Decoder filters 
2015-05-05 11:09:39[psd]:  Encoder filters 
2015-05-05 11:09:40[psd]:  ==> iteration = 1000, average loss = 91.961658188627 
2015-05-05 11:09:40[psd]:  Decoder filters 
2015-05-05 11:09:40[psd]:  Encoder filters 
2015-05-05 11:09:40[psd]:  ==> training model 
2015-05-05 11:09:41[psd]:  Progress: 325 / 500 
2015-05-05 11:09:41[psd]:  ==> iteration = 500, average loss = 79.35829362525 
2015-05-05 11:09:41[psd]:  Decoder filters 
2015-05-05 11:09:41[psd]:  Encoder filters 
2015-05-05 11:09:41[psd]:  ==> iteration = 1000, average loss = 83.730891410127 
2015-05-05 11:09:41[psd]:  Decoder filters 
2015-05-05 11:09:41[psd]:  Encoder filters 
2015-05-05 11:09:43[psd]:  ==> training model 
2015-05-05 11:09:44[psd]:  ==> iteration = 500, average loss = 84.282171071735 
2015-05-05 11:09:44[psd]:  Decoder filters 
2015-05-05 11:09:44[psd]:  Encoder filters 
2015-05-05 11:09:44[psd]:  ==> iteration = 1000, average loss = 81.84496305721 
2015-05-05 11:09:44[psd]:  Decoder filters 
2015-05-05 11:09:44[psd]:  Encoder filters 
2015-05-05 11:09:45[psd]:  ==> training model 
2015-05-05 11:09:46[psd]:  ==> iteration = 500, average loss = 84.875951415577 
2015-05-05 11:09:46[psd]:  Decoder filters 
2015-05-05 11:09:46[psd]:  Encoder filters 
2015-05-05 11:09:46[psd]:  ==> iteration = 1000, average loss = 79.518613600991 
2015-05-05 11:09:46[psd]:  Decoder filters 
2015-05-05 11:09:46[psd]:  Encoder filters 
2015-05-05 11:09:47[psd]:  ==> training model 
2015-05-05 11:09:47[psd]:  ==> iteration = 500, average loss = 85.529133010854 
2015-05-05 11:09:47[psd]:  Decoder filters 
2015-05-05 11:09:48[psd]:  Encoder filters 
2015-05-05 11:09:48[psd]:  ==> iteration = 1000, average loss = 81.033124095493 
2015-05-05 11:09:48[psd]:  Decoder filters 
2015-05-05 11:09:48[psd]:  Encoder filters 
2015-05-05 11:09:49[psd]:  ==> training model 
2015-05-05 11:09:49[psd]:  ==> iteration = 500, average loss = 86.426267457765 
2015-05-05 11:09:49[psd]:  Decoder filters 
2015-05-05 11:09:49[psd]:  Encoder filters 
2015-05-05 11:09:50[psd]:  ==> iteration = 1000, average loss = 79.222386380249 
2015-05-05 11:09:50[psd]:  Decoder filters 
2015-05-05 11:09:50[psd]:  Encoder filters 
2015-05-05 11:09:50[psd]:  ==> training model 
2015-05-05 11:09:51[psd]:  ==> iteration = 500, average loss = 81.807069259763 
2015-05-05 11:09:51[psd]:  Decoder filters 
2015-05-05 11:09:51[psd]:  Encoder filters 
2015-05-05 11:09:52[psd]:  ==> iteration = 1000, average loss = 81.693027863949 
2015-05-05 11:09:52[psd]:  Decoder filters 
2015-05-05 11:09:52[psd]:  Encoder filters 
2015-05-05 11:09:58[psd]:  ==> training model 
2015-05-05 11:09:59[psd]:  ==> iteration = 500, average loss = 83.291252593902 
2015-05-05 11:09:59[psd]:  Decoder filters 
2015-05-05 11:09:59[psd]:  Encoder filters 
2015-05-05 11:09:59[psd]:  ==> iteration = 1000, average loss = 82.476883418718 
2015-05-05 11:09:59[psd]:  Decoder filters 
2015-05-05 11:09:59[psd]:  Encoder filters 
2015-05-05 11:10:28[psd]:  ==> constructed linear auto-encoder 
2015-05-05 11:10:28[psd]:  ==> constructed linear auto-encoder 
2015-05-05 11:10:36[psd]:  ==> training model 
2015-05-05 11:10:36[psd]:  ==> iteration = 500, average loss = 140.28590728214 
2015-05-05 11:10:36[psd]:  Decoder filters 
2015-05-05 11:10:36[psd]:  Encoder filters 
2015-05-05 11:10:37[psd]:  ==> iteration = 1000, average loss = 119.26223741266 
2015-05-05 11:10:37[psd]:  Decoder filters 
2015-05-05 11:10:37[psd]:  Encoder filters 
2015-05-05 11:10:37[psd]:  ==> training model 
2015-05-05 11:10:51[psd]:  ==> training model 
2015-05-05 11:10:51[psd]:  ==> iteration = 500, average loss = 109.97712459311 
2015-05-05 11:10:51[psd]:  Decoder filters 
2015-05-05 11:10:51[psd]:  Encoder filters 
2015-05-05 11:10:52[psd]:  ==> iteration = 1000, average loss = 98.837661502537 
2015-05-05 11:10:52[psd]:  Decoder filters 
2015-05-05 11:10:52[psd]:  Encoder filters 
2015-05-05 11:12:18[psd]:  table: 0x0e46c8e0 
2015-05-05 11:12:41[psd]:  table: 0x0e69bf60 
2015-05-05 11:12:44[psd]:  -0.0882
-0.0696
-0.0376
 0.0028
 0.0895
 0.4390
 0.4830
 0.3230
 0.1801
 0.3687
-0.1977
-1.0035
-0.9668
-0.5506
 1.0683
 0.6349
-0.3263
-0.1559
 0.2896
 0.6253
 0.3811
-0.6080
-0.4157
-0.1326
-0.8011
-0.0569
-0.1242
-0.1903
-0.1694
-0.1107
-0.1074
 0.1522
 0.1955
 0.5183
 0.6192
-0.0511
-0.3129
 0.3169
 0.6507
 1.1324
 0.6960
 0.0897
 0.1678
 0.1545
 0.2533
 0.1128
-0.2681
-0.4733
-0.1095
-0.2419
-0.0429
-0.0568
-0.0744
-0.0535
-0.0656
-0.2252
-0.1289
-0.0887
-0.1464
 0.1044
 0.2380
 0.5691
 0.7554
 0.3209
 1.0056
 0.6544
-0.2662
-0.0175
-0.0381
-0.0025
-0.1212
-0.1627
-0.2487
 0.0072
 0.2191
 0.1210
 0.1824
-0.1212
 0.0617
-0.0793
 0.0135
-0.0829
-0.1869
-0.1188
-0.1961
-0.2430
-0.1833
-0.2860
-0.5335
 1.0659
 0.3267
-1.0392
-0.5068
-0.1341
-0.1830
-0.1391
-0.1273
-0.1161
-0.0576
 0.2583
 0.0493
 0.1482
 0.1015
 0.0690
-0.0883
-0.0127
 0.1002
-0.0366
-0.1097
-0.1478
-0.2879
-0.4304
-0.6742
-0.4268
 1.5756
 0.6247
-0.8547
-0.4657
-0.3657
-0.2796
-0.1116
-0.1944
-0.1498
-0.1357
 0.1845
-0.8795
-0.4063
 0.0837
 0.1405
 0.1788
 0.0413
-0.0394
 0.0536
-0.0378
-0.0249
-0.0845
-0.1383
-0.5865
-0.3740
 1.2519
 0.3943
-0.5701
-0.1882
-0.2134
 0.0338
 0.0034
-0.0919
-0.1378
-0.1847
 0.0506
 0.2241
-0.5794
-0.8928
-0.6994
-0.2435
 0.1964
 0.1714
 0.1473
 0.2349
 0.0591
 0.1270
-0.0124
-0.4923
-0.2837
 1.4713
 0.3947
-0.5159
-0.2240
-0.0226
 0.0535
 0.0796
 0.0906
 0.0242
-0.1268
-0.0865
 1.5795
 1.6617
 0.5050
-0.8207
-0.9378
-0.4724
 0.1397
 0.0335
 0.3382
 0.4202
 0.3779
 0.2226
-0.3938
-0.0808
 1.8269
 0.1900
-0.4781
-0.2429
 0.0018
-0.0688
 0.0394
 0.0448
 0.0213
-0.0134
-0.0114
-0.4967
 0.6581
 1.7574
 1.6993
 0.9853
 0.0719
-0.3033
-0.4252
-0.1951
 0.0708
 0.2153
 0.4193
 0.0342
 0.2116
 1.4035
-0.2974
-0.4023
-0.1643
 0.0102
-0.0489
-0.0362
-0.0810
 0.0037
 0.0381
 0.0671
-0.8465
-0.8434
-0.2803
 0.7754
 1.7754
 1.0125
-0.4254
-0.3453
-0.3038
-0.3984
-0.2935
-0.3226
-0.3448
 0.0376
 0.9613
-0.1695
-0.2306
-0.2125
-0.0616
-0.0183
-0.0100
 0.0082
 0.0894
-0.0564
 0.0372
-0.4059
-0.4687
-0.5518
-0.6239
 0.0384
 0.2973
-0.2362
-0.2133
-0.1868
-0.1736
-0.1864
-0.4376
-0.7235
-0.2347
 0.6859
-0.1088
-0.1724
 0.0662
 0.0422
 0.0547
 0.0589
 0.0949
 0.0339
-0.0127
-0.0974
-0.3620
-0.1186
-0.2426
-0.3580
-0.0651
 0.0063
-0.3671
-0.1887
-0.0449
-0.0494
-0.1202
-0.2189
-0.5734
-0.3783
 1.2348
-0.0344
-0.4890
 0.1467
 0.0871
 0.0229
-0.0238
 0.1147
 0.0323
 0.0385
-0.0274
-0.0114
-0.1869
-0.2743
-0.2690
 0.0782
 0.0518
-0.2360
-0.0535
-0.0190
 0.0152
-0.0854
-0.2751
-0.7084
-0.0524
 2.1137
-0.3280
-0.6334
-0.0614
 0.0676
-0.0786
-0.0713
-0.0664
-0.0788
-0.1795
-0.3088
 0.1444
-0.4433
-0.1424
-0.1414
 0.2408
 0.1551
-0.1598
-0.0215
 0.0018
-0.0650
-0.0997
-0.3097
-0.9120
 0.9440
 1.9178
-0.7373
-0.5180
-0.2196
 0.0025
 0.0103
-0.2133
-0.2730
-0.3014
-0.5123
-0.2537
 0.2361
-0.4772
-0.2118
-0.1334
 0.1944
 0.1440
-0.2107
-0.0605
 0.0021
-0.1478
-0.1530
-0.5079
-0.8097
 1.7030
 0.5826
-0.8772
-0.3373
-0.1514
-0.0711
 0.1193
-0.0906
-0.4605
-0.6147
-0.2227
 0.7201
 0.4113
-0.1715
-0.4877
-0.1733
 0.0809
 0.2433
-0.0427
-0.1504
-0.1164
-0.0852
-0.2741
-0.8473
-0.1024
 1.8514
-0.4950
-0.7152
-0.1899
-0.0621
-0.1799
-0.1591
-0.2835
-0.4260
-0.2177
 0.7433
 1.2625
 0.3904
 0.2492
-0.4067
-0.3240
-0.2495
 0.1472
 0.1439
-0.2128
-0.2411
-0.1259
-0.4832
-0.9500
 0.9399
 1.4200
-0.8353
-0.6112
-0.1547
-0.2239
-0.2785
-0.4080
-0.4333
 0.1653
 0.7394
 1.0391
 0.4425
 0.0870
 0.4024
-0.0779
-0.3857
-0.2397
 0.0142
 0.2618
-0.0767
-0.2161
-0.3908
-0.8238
-0.7718
 1.7097
 0.8950
-1.0967
-0.6297
-0.3120
-0.3468
-0.4598
-0.3281
 0.2281
 0.7911
 1.1177
 0.5847
-0.6193
-0.2334
 0.1893
 0.1218
-0.3529
-0.2436
-0.1928
 0.3430
 0.2591
-0.0351
-0.3470
-1.1992
-0.2918
 2.0552
 0.3587
-1.3860
-0.9321
-0.6385
-0.5468
 0.1534
 0.5189
 0.4765
 0.9494
 0.5402
-0.2797
-0.5907
-0.6993
-0.1300
 0.3685
-0.2666
-0.3912
-0.2464
 0.0775
 0.0780
-0.1294
-0.8037
-1.5033
 0.4513
 1.5079
 0.4048
-0.1866
 0.4246
 0.8732
 0.1533
 0.1688
 0.2667
 0.7676
 0.3694
-0.4454
-0.2451
-0.1583
-0.6601
-0.5029
 0.0936
 0.0214
-0.4251
-0.4107
-0.2847
-0.3303
-0.4207
 0.6631
 0.2380
 1.1502
 1.2155
 0.4627
 0.4197
 0.3254
 0.4072
-0.3794
-0.3328
 0.5927
 0.3084
-0.4696
-0.4789
-0.1844
 0.0564
 0.6731
-0.9207
-0.1038
 0.0226
-0.4387
-0.5855
-0.5892
-0.6797
 0.9443
 2.4650
 0.8654
-0.0006
 0.5105
-0.7587
-1.3630
-0.7931
 0.1140
-0.2425
 0.6174
 0.4694
-0.4679
-0.4535
-0.1247
-0.0804
-0.0707
 1.9600
-0.2254
-0.5885
 0.0637
-0.3221
-0.7800
-1.1025
 0.3450
 1.3167
 0.1118
-0.5120
 0.1096
 1.7888
-0.5745
-1.0601
 0.0174
 0.2396
 0.7367
 0.3163
-0.4564
-0.4244
-0.1291
-0.1204
-0.1072
-0.1012
 1.3401
 1.5547
-0.6908
-0.4216
-0.3911
-0.7581
-0.5568
-0.5085
 0.0552
 0.9735
-0.2962
-0.4853
 0.3034
-0.6845
-0.1987
 0.3461
 0.6400
 0.1445
-0.5071
-0.3164
-0.0687
-0.1291
-0.0687
-0.1332
 0.0623
-0.4387
 1.9437
 0.7949
-0.7506
-0.2036
-0.2196
-0.6276
 0.2416
 1.8825
 0.8598
-1.1596
-0.1916
 0.0885
-0.3653
 0.2418
 0.4069
-0.0116
-0.6056
-0.4467
-0.1205
-0.0581
-0.0521
-0.0759
-0.0496
 0.0866
[torch.DoubleTensor of size 625]
 
2015-05-05 11:15:08[psd]:  
2015-05-05 11:15:13[psd]:  table: 0x126ce320 
2015-05-05 11:15:23[psd]:  0 
2015-05-05 11:15:27[psd]:  function: 0x0e46c908 
2015-05-05 11:15:30[psd]:  5000 
2015-05-05 11:15:38[psd]:  table: 0x0e43fae0 
2015-05-05 11:15:42[psd]:  -0.2757
 0.0286
-0.3423
 0.2052
-0.1814
-0.3337
-0.3990
 0.0624
-0.0096
-0.0140
-0.3732
-0.0013
-0.0414
-0.2535
-0.4752
-0.3215
 0.2949
 0.2274
 0.2844
-0.1080
 0.4602
 0.1896
 0.1501
 0.0132
 0.0348
 0.0329
 0.1967
 0.1294
 0.1198
 0.1353
-0.2187
 0.1886
 0.2620
-0.0447
 0.2152
-0.2903
 0.0396
-0.1090
-0.0987
 0.0641
-0.1316
-0.1643
-0.4199
-0.1948
-0.2845
-0.2184
-0.2072
 0.1598
 0.1913
-0.0464
-0.3135
 0.0618
 0.2042
 0.0294
-0.1330
-0.1426
-0.2661
-0.0712
-0.2333
-0.2627
-0.0323
-0.1227
 0.3194
 0.1245
-0.1693
 0.0459
 0.0238
 0.1933
 0.2888
-0.0077
-0.1177
 0.0253
-0.3138
 0.0508
-0.0434
-0.1674
-0.1996
 0.2096
 0.2002
 0.0994
 0.1472
 0.2507
-0.1892
-0.3945
-0.1529
-0.0018
-0.0096
 0.1829
-0.2631
 0.1203
 0.2178
-0.1126
 0.0963
-0.2958
-0.0808
-0.3545
 0.2206
 0.0198
-0.1838
 0.3584
[torch.DoubleTensor of size 100]
 
2015-05-05 11:21:05[psd]:  ==> training model 
2015-05-05 11:22:39[psd]:  ==> training model 
2015-05-05 11:22:39[psd]:  ==> iteration = 500, average loss = 168.40386026263 
2015-05-05 11:22:39[psd]:  Decoder filters 
2015-05-05 11:22:39[psd]:  Encoder filters 
2015-05-05 11:22:40[psd]:  ==> iteration = 1000, average loss = 161.96564755305 
2015-05-05 11:22:40[psd]:  Decoder filters 
2015-05-05 11:22:40[psd]:  Encoder filters 
2015-05-05 11:23:14[psd]:  table: 0x14eceb40 
2015-05-05 11:23:57[psd]:  5000 
2015-05-05 11:24:03[psd]:  table: 0x0e01c228 
2015-05-05 11:24:10[psd]:  table: 0x14e71be0 
2015-05-05 11:24:15[psd]:  table: 0x14e71ad8 
2015-05-05 11:24:35[psd]:  ==> training model 
2015-05-05 11:26:49[psd]:  -0.1524
-0.1220
 0.2516
-0.0845
 0.0784
 0.0807
 0.1234
 0.0042
-0.1819
-0.1477
 0.1514
-0.1056
 0.1676
-0.2292
-0.0825
 0.1089
[torch.DoubleTensor of size 16]
 
2015-05-05 11:27:14[psd]:  unsup.AutoEncoder 
2015-05-05 11:27:25[psd]:  ==> constructed linear auto-encoder 
2015-05-05 11:27:25[psd]:  ==> constructed linear auto-encoder 
2015-05-05 11:27:29[psd]:  unsup.AutoEncoder 
2015-05-05 11:27:35[psd]:  ==> training model 
2015-05-05 11:27:36[psd]:  ==> iteration = 500, average loss = 162.95514694092 
2015-05-05 11:27:36[psd]:  Decoder filters 
2015-05-05 11:27:36[psd]:  Encoder filters 
2015-05-05 11:27:36[psd]:  ==> iteration = 1000, average loss = 158.35739877511 
2015-05-05 11:27:36[psd]:  Decoder filters 
2015-05-05 11:27:36[psd]:  Encoder filters 
2015-05-05 11:27:41[psd]:   0.1146
 0.1411
-0.0765
-0.4862
 0.0466
-0.0487
 0.2404
 0.1577
 0.1830
-0.2374
-0.0722
 0.3385
 0.2912
-0.3700
-0.4470
 0.3373
[torch.DoubleTensor of size 16]
 
2015-05-05 11:28:50[psd]:  ==> constructed linear auto-encoder 
2015-05-05 11:28:50[psd]:  ==> constructed linear auto-encoder 
2015-05-05 11:28:52[psd]:  ==> training model 
2015-05-05 11:28:53[psd]:  ==> iteration = 500, average loss = 129.86880745437 
2015-05-05 11:28:53[psd]:  Decoder filters 
2015-05-05 11:28:53[psd]:  Encoder filters 
2015-05-05 11:28:53[psd]:  ==> iteration = 1000, average loss = 125.26145651436 
2015-05-05 11:28:53[psd]:  Decoder filters 
2015-05-05 11:28:54[psd]:  Encoder filters 
2015-05-05 11:29:02[psd]:   0.2252
 0.4675
-0.3374
 0.3483
-0.6947
-0.6197
-0.5712
 0.3553
-0.1209
-0.1502
-0.4286
 0.2206
-0.1248
-0.0559
-0.2443
 0.4524
-0.3442
-0.0396
 0.1924
 0.0027
 0.1274
 0.0801
 0.3723
-0.6911
 0.2963
-0.3139
-0.2185
-0.3966
-0.2032
 0.5627
 0.1027
-0.7063
-0.7090
 0.2868
-0.1722
-0.0694
-0.0539
-0.1705
 0.0870
-0.4548
-0.2159
-0.1756
 0.0793
 0.2677
-0.0799
-0.5023
-0.3126
 0.6011
 0.2021
-0.3727
-0.0238
-0.5580
-0.4252
 0.2627
-0.3133
-0.3085
 0.3655
 0.1392
-0.3604
-0.4348
-0.1549
 0.7183
-0.1265
-0.1127
 0.6204
 0.3611
 0.0143
-0.2693
 0.3631
 0.2464
 0.0725
-0.0178
 0.2941
-0.0074
-0.2567
 0.1592
-0.0594
 0.4687
 0.2867
 0.2370
 0.0352
 0.5420
 0.2195
 0.5811
 0.3116
-0.1495
-0.0290
-0.0148
 0.4213
-0.2570
 0.0954
-0.3046
 0.4917
-0.1546
 0.0902
-0.5076
 0.4605
-0.1265
-0.1360
-0.3328
[torch.DoubleTensor of size 100]
 
2015-05-05 11:29:08[psd]:  ==> training model 
2015-05-05 11:29:08[psd]:  ==> iteration = 500, average loss = 1.0527033055705 
2015-05-05 11:29:08[psd]:  Decoder filters 
2015-05-05 11:29:08[psd]:  Encoder filters 
2015-05-05 11:29:08[psd]:  ==> iteration = 1000, average loss = 1.5784121710247e-07 
2015-05-05 11:29:08[psd]:  Decoder filters 
2015-05-05 11:29:08[psd]:  Encoder filters 
2015-05-05 11:29:08[psd]:  unsup.AutoEncoder 
2015-05-05 11:29:22[psd]:  ==> training model 
2015-05-05 11:29:22[psd]:  ==> iteration = 500, average loss = 1.4161766461433e-14 
2015-05-05 11:29:22[psd]:  Decoder filters 
2015-05-05 11:29:22[psd]:  Encoder filters 
2015-05-05 11:29:22[psd]:  ==> iteration = 1000, average loss = 1.3585706875321e-21 
2015-05-05 11:29:22[psd]:  Decoder filters 
2015-05-05 11:29:22[psd]:  Encoder filters 
